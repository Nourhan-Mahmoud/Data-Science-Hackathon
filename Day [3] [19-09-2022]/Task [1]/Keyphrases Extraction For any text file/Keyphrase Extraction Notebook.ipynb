{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7H8zTXB4v_n"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/boudinfl/pke.git\n",
    "!pip install matplotlib\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "#Recommended to run on colab "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CEUMajaPAOC"
   },
   "source": [
    "# Explore and Prepare Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6wwkcNc9UzR"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIA3XZ9x8bX3"
   },
   "outputs": [],
   "source": [
    "with open('/content/ComputerScience.txt') as f:\n",
    "    txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qef2cDCd82ZK"
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnIYVXV48tXb"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNllD7ET7clh"
   },
   "outputs": [],
   "source": [
    "txt = txt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_QYF8_P8-MP"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfqFvcfXBtNe"
   },
   "outputs": [],
   "source": [
    "txt = re.sub(r'\\n','',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvrtluR3Bu2f"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfsdeaUT9r63"
   },
   "outputs": [],
   "source": [
    "txt = re.sub(r'-','',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0wO6VBc9ucs"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPjZqZeI-COt"
   },
   "outputs": [],
   "source": [
    "txt = re.sub(r'\"','',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REVWA1wv-FoV"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaERZ6YP-UKD"
   },
   "outputs": [],
   "source": [
    "txt = re.sub(r\"[0-9]\",\"\",txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpu38zO7-ZPE"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqEvWpAb-6pL"
   },
   "outputs": [],
   "source": [
    "txt = re.sub(r\"'\",'',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0l5bpwz-6mU"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlysoIZO_ECc"
   },
   "outputs": [],
   "source": [
    "txt = re.sub(r\";\",'',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPkP4AQt_F3A"
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuHTuCOXNhOv"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVc9U_F9t5Ph"
   },
   "outputs": [],
   "source": [
    "All_top = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D031YGoyrHY8"
   },
   "source": [
    "# Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyNu4bsF9bP4"
   },
   "outputs": [],
   "source": [
    "import pke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yn1jO2QNOwJP"
   },
   "source": [
    "## Graph Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pyu08LFqJKK"
   },
   "source": [
    "### TopicRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDQ_YDrc_Xa3"
   },
   "source": [
    "**NOTES on TopicRank**:\n",
    "* unsupervised graph-based ranking model to keyphrase extraction\n",
    "* uses a random walk algorithm -> to estimate the importance of each topic (node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbVmxaCPp7Uf"
   },
   "outputs": [],
   "source": [
    "# initialize a TopicRank keyphrase extraction model\n",
    "extractor = pke.unsupervised.TopicRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-VKU8AGAXYR"
   },
   "outputs": [],
   "source": [
    "extractor.load_document(input=txt, language='en') # used to pre-process the text (sentence splitting, tokenization, Part-of-Speech tagging, stemming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BK2FOJSnoUqW"
   },
   "outputs": [],
   "source": [
    "extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbBwPbDQC3St"
   },
   "outputs": [],
   "source": [
    "extractor.candidate_selection()  #identifying keyphrase candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkSK3-2EIFB5"
   },
   "source": [
    " In **TopicRank**, candidate weighting is a three-step process:\n",
    "1. candidate clustering (grouping keyphrase candidates into topics)\n",
    "2. graph construction (building a complete-weighted-graph of topics)\n",
    "3. rank topics (nodes) using a random walk algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_c5rs8sRGnGN"
   },
   "outputs": [],
   "source": [
    "extractor.candidate_weighting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPEG9l_XL76f"
   },
   "outputs": [],
   "source": [
    "# Get the N-best candidates (here, 5) as keyphrases\n",
    "keyphrases = extractor.get_n_best(n=20, stemming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QB6UrF7fouOS"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mrtOC6FuHxk"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMVK_XHbqbK4"
   },
   "source": [
    "### MultipartiteRank Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yChGgSAEqiiV"
   },
   "outputs": [],
   "source": [
    "extractor = pke.unsupervised.MultipartiteRank()\n",
    "\n",
    "extractor.load_document(input=txt, language='en')\n",
    "\n",
    "extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")\n",
    "\n",
    "extractor.grammar_selection()\n",
    "\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "keyphrases = extractor.get_n_best(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ktwwug1q2Zi"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQmloPIhuTy5"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtYnapIMtZMY"
   },
   "source": [
    "### TopicalPageRank Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydokqm3htesM"
   },
   "outputs": [],
   "source": [
    "extractor = pke.unsupervised.TopicalPageRank()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input=txt,\n",
    "                        language='en')\n",
    "\n",
    "extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")\n",
    "\n",
    "# 3. select the noun phrases as keyphrase candidates.\n",
    "extractor.candidate_selection()\n",
    "\n",
    "# 4. weight the keyphrase candidates using Single Topical PageRank.\n",
    "#    Builds a word-graph in which edges connecting two words occurring\n",
    "#    in a window are weighted by co-occurrence counts.\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "keyphrases = extractor.get_n_best(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0J8H0F5txfQ"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVdMShnourYg"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBKBjOjzNjm8"
   },
   "source": [
    "## Statistical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B596beOzNrQH"
   },
   "source": [
    "### FirstPhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-veVuRegTBz1"
   },
   "outputs": [],
   "source": [
    " # 1. create a FirstPhrases baseline extractor.\n",
    "extractor = pke.unsupervised.FirstPhrases()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input=txt,language='en')\n",
    "\n",
    "extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")\n",
    "\n",
    "# 3. select the longest sequences of nouns and adjectives as candidates.\n",
    "extractor.candidate_selection()\n",
    "\n",
    "# 4. weight the candidates using their position\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "keyphrases = extractor.get_n_best(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzYdusjGjV9v"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzuR4CpLu2EY"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEzuRj_PScOH"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnKoh6b3Sg8N"
   },
   "outputs": [],
   "source": [
    "extractor = pke.unsupervised.TfIdf()        # initialize a keyphrase extraction model, here TFxIDF\n",
    "\n",
    "extractor.load_document(input=txt)       # load the content of the document (str or spacy Doc)\n",
    "\n",
    "extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")\n",
    "\n",
    "extractor.candidate_selection()             # identify keyphrase candidates\n",
    "\n",
    "extractor.candidate_weighting()             # weight keyphrase candidates\n",
    "\n",
    "keyphrases = extractor.get_n_best(n=20)      # select the 5-best candidates as keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejxac1NqSmlj"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRECIEfTu_vj"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtoKjz3uk8TE"
   },
   "source": [
    "### KPMiner Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XU6zkC1aSr6M"
   },
   "outputs": [],
   "source": [
    "# 1. create a KPMiner extractor.\n",
    "extractor = pke.unsupervised.KPMiner()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "extractor.load_document(input=txt,language='en')\n",
    "\n",
    "# 3. select {1-5}-grams that do not contain punctuation marks or\n",
    "#    stopwords as keyphrase candidates. Set the least allowable seen\n",
    "#    frequency to 5 and the number of words after which candidates are\n",
    "#    filtered out to 200.\n",
    "lasf = 5\n",
    "cutoff = 200\n",
    "extractor.candidate_selection(lasf=lasf, cutoff=cutoff)\n",
    "\n",
    "# 4. weight the candidates using KPMiner weighting function.\n",
    "#df = pke.load_document_frequency_file(input_file=\"path/to/df.tsv.gz\")\n",
    "\n",
    "#alpha = 2.3\n",
    "#sigma = 3.0\n",
    "# df=df, alpha=alpha, sigma=sigma\n",
    "\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "keyphrases = extractor.get_n_best(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCBeWvQ6kxhk"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FD-8M6r7mxF2"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13c9elE_pD4t"
   },
   "source": [
    "# Supervised\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YQmCNAZpNVw"
   },
   "source": [
    "### Kea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyLD42bRpDKT"
   },
   "outputs": [],
   "source": [
    "# 1. create a Kea extractor.\n",
    "extractor = pke.supervised.Kea()\n",
    "\n",
    "# 2. load the content of the document.\n",
    "stoplist = pke.lang.stopwords.get('en')\n",
    "extractor.load_document(input=txt, language='en')\n",
    "\n",
    "# 3. select 1-3 grams that do not start or end with a stopword as\n",
    "#    candidates. Candidates that contain punctuation marks as words\n",
    "#    are discarded.\n",
    "extractor.candidate_selection()\n",
    "\n",
    "# 4. classify candidates as keyphrase or not keyphrase.\n",
    "#df = pke.load_document_frequency_file(input_file='path/to/df.tsv.gz')\n",
    "#model_file = 'path/to/kea_model'\n",
    "#model_file=model_file,df=df\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "# 5. get the 10-highest scored candidates as keyphrases\n",
    "keyphrases = extractor.get_n_best(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsPbeX_rpqaY"
   },
   "outputs": [],
   "source": [
    "All_top.extend(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieewaNZPpsNa"
   },
   "outputs": [],
   "source": [
    "All_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PScxChevXz_"
   },
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68rSGw6Mv0jf"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owkepdkxvQwn"
   },
   "outputs": [],
   "source": [
    "x = np.array(All_top)\n",
    "u = np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5NrfLKbyvhV"
   },
   "outputs": [],
   "source": [
    "z = u[118:]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZEKw-t0vgnx"
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in z:\n",
    "  cnt = 0\n",
    "  for ii in range(len(All_top)):\n",
    "    if i == All_top[ii][0]:\n",
    "      cnt += 1\n",
    "  if cnt >=2:\n",
    "    l.append(i)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0i3Jp7XVxl2D"
   },
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTuYF7Nd2kJd"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "  \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "def tokenize_sentences(text):\n",
    "    sentences = [sent_tokenize(text)]\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    # Remove any short sentences less than 20 letters.\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
    "    return sentences\n",
    "\n",
    "def get_sentences_for_keyword(keywords, sentences):\n",
    "    keyword_processor = KeywordProcessor()\n",
    "    keyword_sentences = {}\n",
    "    for word in keywords:\n",
    "        keyword_sentences[word] = []\n",
    "        keyword_processor.add_keyword(word)\n",
    "    for sentence in sentences:\n",
    "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
    "        for key in keywords_found:\n",
    "            keyword_sentences[key].append(sentence)\n",
    "\n",
    "    for key in keyword_sentences.keys():\n",
    "        values = keyword_sentences[key]\n",
    "        values = sorted(values, key=len, reverse=True)\n",
    "        keyword_sentences[key] = values\n",
    "    return keyword_sentences\n",
    "\n",
    "sentences = tokenize_sentences(txt)\n",
    "keyword_sentence_mapping = get_sentences_for_keyword(l, sentences)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnswTOgh5KSl"
   },
   "outputs": [],
   "source": [
    "keyword_sentence_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1y1RrxK6_gH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
